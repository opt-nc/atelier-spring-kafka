<!doctype html>
<html xmlns="http://www.w3.org/1999/html">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>Spring for Apache Kafka</title>

        <link rel="stylesheet" href="dist/reset.css">
        <link rel="stylesheet" href="dist/reveal.css">
        <link rel="stylesheet" href="dist/theme/black.css" id="theme">

        <!-- Theme used for syntax highlighted code -->
        <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
        <link rel="stylesheet" href="plugin/verticator/verticator.css">
    </head>
    <body>
        <div class="reveal">
            <div class="slides">
                <section data-background-image="img/spring.jpg" data-background-opacity="0.5">

                    <img style="-webkit-filter:drop-shadow(0px 0px 6px black); filter:drop-shadow(0px 0px 6px black);" src="img/icons/springframework.png">
                    <img src="img/icons/kafka.png">

                    <h1 style="text-shadow: 0px 0px 7px black">Spring for Apache Kafka</h1>
                </section>
                <section data-background-image="img/kafka-cas-usage_opt.png" data-background-opacity="0.5">
                    <ul>
                        <li>Développé chez LinkedIn, et maintenu au sein de la fondation Apache depuis 2012.</li>
                        <li>Poussé par Confluent, plateforme créée autour de Kafka.</li>
                    </ul>
                </section>
                <section>
                    <h3>Mais c’est quoi Apache Kafka ?</h3>
                    <ul>
                        <li>Système de stockage de flux de  <span style="color: chartreuse">messages</span> (streams of records)</li>
                        <li>Asynchrone</li>
                        <li>Permet de gérer des gros volumes de données, faible latence</li>
                        <li>Tout en assurant une sécurité des données</li>
                        <li>Aucun type de message, que des streams</li>
                    </ul>
                </section>
                <section>
                    <h3>Messages</h3>
                    <ul>
                        <li>Composés d’une valeur, d’une clé, et d’un timestamp</li>
                        <li>Sont organisés en catégories appelées  <span style="color: chartreuse">topics</span></li>
                    </ul>
                </section>
                <section>
                    <section>
                        <h3>Topics / Consumer / Producer</h3>
                        <img style="width: 70%;" data-src="img/log_consumer.png">
                    </section>
                    <section>
                        <ul>
                            <li>Les topics ne sont pas modifiables à l’exception de l’ajout de messages à la fin</li>
                            <li>Le  <span style="color: chartreuse">producer</span> ajoute des messages à la fin des topics de son choix</li>
                            <li>Le  <span style="color: chartreuse">consumer</span> lit des topics toujours dans l’ordre, c’est-à-dire du plus ancien message au plus récent</li>
                        </ul>
                    </section>
                </section>
                <section>
                    <h4>Plateforme de streaming distribuée</h4>
                    <img style="width: 70%; -webkit-filter:drop-shadow(0px 0px 3px white); filter:drop-shadow(0px 0px 3px white);" data-src="img/kafka-apis_connectors.png">
                </section>
                <section>
                    <h2>RIP opt-kakfa</h2>
                    <ul>
                        <li>Nouvelle stratégie SMO : ne plus maintenir de lib "maison"</li>
                        <li>Abandon de la lib <span style="color: turquoise">opt-kafka</span> (utilisation de la lib Apache Kafka) au profit de <span style="color: chartreuse">Spring for Apache Kafka</span></li>
                    </ul>
                </section>
                <section data-background-image="img/spring.png" data-background-opacity="0.05">
                    <h3>Spring Apache for Kafka</h3>
                    MAVEN
<pre><code class="xml"><dependency>
   <groupId>org.springframework.kafka</groupId>
   <artifactId>spring-kafka</artifactId>
</dependency></code></pre>
                    GRADLE
                    <pre><code>compile 'org.springframework.kafka:spring-kafka'</code></pre>
                    PROPRIÉTÉS
                    <pre><code class="properties">spring.kafka.bootstrap-servers=${KAFKA_BROKERS_HOST}</code></pre>
                </section>
                <section data-background-image="img/docker.png" data-background-opacity="0.3">
                    <h3>développement en local</h3>
                    <pre><code class="yml" data-line-numbers="4-8|10-20">version: "3"
services:

    zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    container_name: zookeeper
    expose:
        - "2181"

    kafka:
    image: wurstmeister/kafka:2.11-2.0.0
    container_name: kafka
    depends_on:
        - zookeeper
    ports:
        - "9092:9092"
    environment:
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
        KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
                    </code></pre>
                </section>
                <section>
                    <h2>Producer</h2>
                    <ul>
                        <li>Produit des données sur les topics</li>
<!--                        <li>Il est responsable d'assigner la données à une partition du topic</li>-->
                        <li>Peut attendre un ACK (accusé réception) pour savoir si la donnée a bien été transmise</li>
                    </ul>
                </section>

                <section>
                    <h4>Configuration</h4>
                    <pre><code data-line-numbers="4-5|15-26|28-31">@Configuration
public class KafkaConfiguration {

    @Autowired
    private KafkaProperties kafkaProperties;

    public static final String ENTREPRISE_KAFKA_TOPIC = &quot;isee.entreprise&quot; ;
    public static final String ETABLISSEMENT_KAFKA_TOPIC = &quot;isee.etablissement&quot; ;

    @Bean
    public ProducerFactory&lt;String, String&gt; producerFactory() {
        return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());
    }

    @Bean
    public Map&lt;String, Object&gt; producerConfigs() {
        Map&lt;String, Object&gt; kafkaProps = new HashMap&lt;&gt;();
        kafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        kafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        kafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        kafkaProps.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);
        kafkaProps.put(ProducerConfig.RETRIES_CONFIG, &quot;1&quot;);
        kafkaProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, &quot;1&quot;);
        kafkaProps.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, &quot;22020096&quot;);
        return kafkaProps;
    }

    @Bean
    public KafkaTemplate&lt;String, String&gt; kafkaTemplate() {
        return new KafkaTemplate&lt;&gt;(producerFactory());
    }

    @Bean
    public KafkaAdmin admin() {
        Map&lt;String, Object&gt; configs = new HashMap&lt;&gt;();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        return new KafkaAdmin(configs);
    }

}</code></pre>
                </section>
                <section>
                    <h4>Producer avec ACK</h4>
                    <pre><code data-line-numbers="6|15-18">@Service
public class ProducerService {

    private static final Logger LOGGER = LoggerFactory.getLogger(ProducerService.class);

    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;

    public ProducerService(KafkaTemplate&lt;String, String&gt; kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public SendResult&lt;String, String&gt; push(String topic, String key, Object data, ObjectMapper objectMapper) {
        try {
            String json = objectMapper.writeValueAsString(data);
            ProducerRecord&lt;String, String&gt; record = new ProducerRecord&gt;(topic, key, json);
            LOGGER.debug("Envoi Kafka : topic=[{}], key=[{}], message=[{}]", record.topic(), record.key(), record.value());
            return kafkaTemplate.send(record).get();

        } catch (JsonProcessingException e) {
            throw new RuntimeException(String.format("Erreur de serialization de l'objet %s destiné au topic %s", key, topic), e);
        } catch (InterruptedException | ExecutionException e) {
            throw new RuntimeException(String.format("Erreur lors de l'envoi de l'objet %s destiné au topic %s", key, topic), e);
        }
    }
}</code></pre>
                </section>
                <section>
                    <h4>Producer mode asynchrone</h4>
                    <pre><code data-line-numbers="3|16-17|20-30">@Service
public class ProducerService {
  private KafkaTemplate&lt;String, String&gt; kafkaTemplate;

    public KafkaService(KafkaTemplate&lt;String, String&gt; kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

 // Envoi asynchrone du message
 public void pushAsync(MessageDTO messageDTO) {
    ObjectMapper objectMapper = new ObjectMapper();
    String json = null;
    try {
         json = objectMapper.writeValueAsString(messageDTO);
         String uuid = UUID.randomUUID().toString();
         ListenableFuture&lt;SendResult&lt;String, String&gt;&gt; future =
              kafkaTemplate.send(messageTopic, json);

         String finalJson = json;
         future.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, String&gt;&gt;() {
           @Override
            public void onSuccess(SendResult&lt;String, String&gt; result) {
                System.out.println("Sent message=[" + finalJson +
                   "] with offset=[" + result.getRecordMetadata().offset() + "]");
             }
           @Override
           public void onFailure(Throwable ex) {
              System.out.println("Unable to send message=["
                    + finalJson + "] due to : " + ex.getMessage());
           }
         });

    } catch (JsonProcessingException e) {
        e.printStackTrace();
    }
 }
}</code></pre>
                </section>
                <section>
                    <h2>Consumer</h2>
                    <ul>
                        <li>Appartient à un consumer group name</li>
                        <li>Chaque message publié dans un topic est consommé par un seul consumer d'un group name</li>
                    </ul>
                </section>
                <section>
                <pre><code data-line-numbers="6|7-11">@Component
public class KafkaConsumer {

   private final Logger log = LoggerFactory.getLogger(KafkaConsumer.class);

   @KafkaListener(id = "messageListener", topics = "${opt.kafka.topics.message}", groupId = "messageG1")
   public void messageListener(ConsumerRecord&#60;String, String> record) throws JsonProcessingException {
      log.info("Reception enregistrement brut de messageListener : [{}]", record);
      ObjectMapper objectMapper = new ObjectMapper();
      MessageDTO messageDTO = objectMapper.readValue(record.value(), MessageDTO.class);
      log.info("Reception message de messageListener : [{}]", messageDTO);
   }
}</code></pre>
                </section>

                <section>
                    <h2>Consumer Stream</h2>
                    <ul>
                        <li>Permet de développer des unités de traitement de messages au fil de l’eau (streaming).</li>
                        <li>Permet de faire des opérations entre topic en temps réel: aggregation / jointure ...</li>
                    </ul>
                </section>
                <section>
                    <h3>Cas d'utilisation - Consumer-SIG</h3>
<!--                    <img style="width: 70%;" data-src="img/bpweb.png">-->
                    <img style="width: 100%; -webkit-filter:drop-shadow(0px 0px 3px white); filter:drop-shadow(0px 0px 3px white);" data-src="img/bpweb.png">
                </section>
                <section>
                    <h3>Cas d'utilisation - Consumer-SIG</h3>
                    <img style="width: 70%;" data-src="img/consumer-SIG.png">
                </section>
				<!-- TEST -->
                <section data-background-image="img/tests.png" data-background-opacity="0.15">
                    <h1>Tests</h1>
                    MAVEN
                    <pre><code class="xml"><dependency>
   <groupId>org.springframework.kafka</groupId>
   <artifactId>spring-kafka-test</artifactId>
   <scope>test</scope>
</dependency></code></pre>
                    GRADLE
                    <pre><code>testCompile 'org.springframework.kafka:spring-kafka-test'</code></pre>
                </section>
                <section>
					<section>
						<h1>Producer</h1>
                    </section>
                    <!-- opt-kafka -->
					<section data-background-image="img/opt_kafka.jpg" data-background-opacity="0.07">
						Exemple <span style="color: turquoise">opt-kafka</span>
                        <pre><code class="java" data-line-numbers="5|15-19|21">public class BPWriterTest {

private BPWriter writer;

private KafkaService kafkaService = Mockito.mock(KafkaService.class) ;

    @Before
    public void init() {
        writer = new BPWriter(kafkaService);
    }

    @Test
    public void testBPWriter() {

        Mockito.when(kafkaService.push(any(), any())).thenReturn(Mockito.mock(KafkaResult.class));

        List&lt;BoitePostaleKafkaDto&gt; dto = new ArrayList&lt;&gt;();
        dto.add(new  BoitePostaleKafkaDto());
        writer.write(dto);

        Mockito.verify(kafkaService, Mockito.times(1)).push(any(), any());
    }

}</code></pre>
                    </section>
					<section data-background-image="img/spring.png" data-background-opacity="0.1">
						Exemple <span style="color: yellow;">@EmbeddedKafka</span>
                    	<pre><code data-line-numbers="1-5|15-16|44-51|29|36-40">@RunWith(SpringRunner.class)
@EmbeddedKafka(topics = {"${opt.kafka.topics.message}"})
@SpringBootTest(
        properties = "spring.kafka.bootstrap-servers=${spring.embedded.kafka.brokers}",
        classes = {KafkaService.class, KafkaAutoConfiguration.class})
public class KafkaServiceTest {

    @Value(value = "${opt.kafka.topics.message}")
    private String messageTopic;

    @Autowired
    private KafkaService kafkaService;

    @SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
    @Autowired
    private EmbeddedKafkaBroker embeddedKafka;

    private static final String AUTHOR = "Great Leader";
    private static final String BODY = "Dear %{Recipient}, foo, Kind Regards";
    private static final Long ID = 12345L;
    private static final String RECIPIENT = "World";
    private static final String SUBJECT = "Hello world";

    @Test
    public void push() {
        final Consumer&lt;String, String&gt; consumer = buildConsumer();

        MessageDTO m = createMessageDTO();
        SendResult&lt;String, String&gt; result = kafkaService.push(m);

        Assert.assertNotNull(result);

        String value = result.getProducerRecord().value();
        String key = result.getProducerRecord().key();

        embeddedKafka.consumeFromEmbeddedTopics(consumer, messageTopic);
        final ConsumerRecord&lt;String, String&gt; record = getSingleRecord(consumer, messageTopic, 10_000);

        assertThat(record, hasValue(value));
        assertThat(record, hasKey(key));

    }

    private &lt;K, V&gt; Consumer&lt;K, V&gt; buildConsumer() {
        final Map&lt;String, Object&gt; props = KafkaTestUtils.consumerProps("g1", "true", embeddedKafka);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);

        final DefaultKafkaConsumerFactory&lt;K, V&gt; consumerFactory = new DefaultKafkaConsumerFactory&lt;&gt;(props);
        return consumerFactory.createConsumer();
    }

    private MessageDTO createMessageDTO() {
        MessageDTO m = new MessageDTO();
        m.setAuthor(AUTHOR);
        m.setBody(BODY);
        m.setId(ID);
        m.setRecipient(RECIPIENT);
        m.setSubject(SUBJECT);
        return m;
    }

}</code></pre>
</section>
                </section>
                <section>
					<section>
						<code>
							<h1>Consumer</h1>
						</code>
					</section>
					<section data-background-image="img/opt_kafka.jpg" data-background-opacity="0.07">
						Exemple <span style="color: turquoise">opt-kafka</span>
						<pre><code class="java" data-line-numbers="7-16|23-29">public class EsiriusTaskTest {

    private EsiriusTask task;

    private IPortailService portailService;

    @Before
    public void setUp() {
        portailService = mock(IPortailService.class);

        Properties streamsConfiguration = new Properties();
        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, "APP_ID");
        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "BOOTSTRAP");
        ObjectMapper mapper = new ObjectMapper().configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
        task = new EsiriusTask(new StreamsConfig(streamsConfiguration), new String[]{BorneKafkaDTO.TOPIC_ESIRIUS}, mapper, portailService);
    }

    @Test
    public void testIsForMe() {
        Assert.assertTrue(task.isForMe("id", "{}"));
    }

    @Test
    public void testProcessNonAP1AP2() {

        task.process("id", "{\"borne\": {\"siteCode\": \"site31\"}}");

        verify(portailService, times(1)).updateBorne(any());
    }

    @Test
    public void testProcessAP1() {

        task.process("id", "{\"borne\": {\"siteCode\": \"AP1\"}}");

        verify(portailService, times(0)).updateBorne(any());
    }

    @Test
    public void testProcessAP2() {

        task.process("id", "{\"borne\": {\"siteCode\": \"AP2\"}}");

        verify(portailService, times(0)).updateBorne(any());
    }
}</code></pre>
					</section>
					<section data-background-image="img/spring.png" data-background-opacity="0.1">
                        Exemple <span style="color: yellow">@EmbeddedKafka</span>
                    <pre><code data-line-numbers="1-5|47-51|38|40-41">@RunWith(SpringRunner.class)
@EmbeddedKafka(topics = {"${opt.kafka.topics.message}"})
@SpringBootTest(
        properties = "spring.kafka.bootstrap-servers=${spring.embedded.kafka.brokers}",
        classes = {KafkaConsumer.class, KafkaAutoConfiguration.class})
public class KafkaConsumerTest {

    @Autowired
    private KafkaConsumer kafkaConsumer;

    @Value(value = "${opt.kafka.topics.message}")
    private String messageTopic;

    @Autowired
    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;

    @SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
    @Autowired
    private EmbeddedKafkaBroker embeddedKafka;

    private static final String AUTHOR = "Great Leader";
    private static final String BODY = "Dear %{Recipient}, foo, Kind Regards";
    private static final Long ID = 12345L;
    private static final String RECIPIENT = "World";
    private static final String SUBJECT = "Hello world";
    private static final String UID = UUID.randomUUID().toString();

    @Test
    public void receive() throws JsonProcessingException, InterruptedException {
        ObjectMapper objectMapper = new ObjectMapper();
        kafkaTemplate = new KafkaTemplate&lt;&gt;(buildProducer());
        kafkaTemplate.setDefaultTopic(messageTopic);
        MessageDTO m = createMessageDTO();
        String json = objectMapper.writeValueAsString(m);

        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(messageTopic, UID, json);

        kafkaTemplate.send(record);

        kafkaConsumer.getLatch().await(10000, TimeUnit.MILLISECONDS);
        assertThat(kafkaConsumer.getLatch().getCount()).isEqualTo(0);

    }



    private ProducerFactory&lt;String, String&gt; buildProducer() {
        final Map&lt;String, Object&gt; props = KafkaTestUtils.producerProps(embeddedKafka.getBrokersAsString());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory&lt;&gt;(props);
    }

    private MessageDTO createMessageDTO() {
        MessageDTO m = new MessageDTO();
        m.setAuthor(AUTHOR);
        m.setBody(BODY);
        m.setId(ID);
        m.setRecipient(RECIPIENT);
        m.setSubject(SUBJECT);
        return m;
    }

}

					</code></pre>
					</section>
                    </code></pre>
                </section>
                <section>
                    <h2>Maintenance de Kafka</h2>
                    <ul>
                        <li>Disponibilité</li>
                        <li>Méthode d'upgrade</li>
                        <li>Maintenance consumers</li>
                    </ul>
                    <h5 style="color: yellow;margin-top: 15px;">Prochain Upgrade 2.4.1 > 2.5.0</h5>
                </section>
                <section>
                    <h3>Problèmatique de la création de nouveaux topics</h3>
                    <ul>
                        <li>Tel que configuré, Kafka laisse le producer créer automatiquement le topic s'il n'existe pas</li>
                        <li>Risque de duplication de la donnée</li>
                    </ul>
                </section>
                <section>
                    <h3>Stratégie</h3>
                    <ul>
                        <li>Consulter le GLIA avant toute création de topic</li>
                        <li>A venir : mise en place par le GLIA d'un référenciel des topics dans Confluence</li>
                    </ul>
                </section>
                <section>
                    <h3>Design for failure</h3>
                    <ul>
                        <li>De plus en plus de clients Kafka vont etre développés</li>
                        <li>Kakfa ne stocke que 48h de données</li>
                        <li>Le consumer doit savoir quel est le dernier offset traité avec succès.</li>
                    </ul>
                </section>
                <section data-background-image="img/optisee.PNG" data-background-opacity="0.1">
                    <h4>Projet utilisant <span style="color: chartreuse">org.springframework.kafka</span></h4>
                    <li>
                        <ul>OPTISEE</ul>
                    </li>
                </section>
                <section data-background-image="img/opt_kafka.jpg" data-background-opacity="0.1">
                    <h4>Clients Kafka</h4>
                        <ul>
                            <li>CLIK</li>
                            <li>SIG (BPWEB)</li>
                            <li>REFCOM</li>
                            <li>REFTEL</li>
                            <li>OPTISEE</li>
                            <li>...</li>
                        </ul>
                </section>
                <section>
                    <section data-background-image="img/livedemo.png" data-background-opacity="0.1">
                    <h2>Démo</h2>
                        <ul>
                            <li>Producer</li>
                            <li>Consumer</li>
                            <li>KStream</li>
                        </ul>
                    </section>
                    <section data-background-image="img/livedemo.png" data-background-opacity="0.02">
                        <h3>Producer</h3>
                        <img data-src="img/livedemoProducer.png">
                        <pre><code>{
    "id": 123465,
    "author": "MailBatch1",
    "subject": "1er message dans Kafka",
    "recipient": "DSI_GLOBAL",
    "body": "Incident !"
}</code></pre>
                    </section>
                    <section data-background-image="img/livedemo.png" data-background-opacity="0.02">
                        <h3>Consumer</h3>
                        <img data-src="img/livedemoConsumer.png">
                        <pre><code>log.info("Reception message de messageListener : [{}]", messageDTO);</code></pre>
                    </section>
                    <section data-background-image="img/livedemo.png" data-background-opacity="0.02">
                        <h3>KStream</h3>
                        <img data-src="img/livedemoKStream.png">
                        <pre><code># sms
{"phoneNumberEmitter":"112233", "message":"Coucou !", "phoneNumberReceiver":"907256"}</code></pre>
                        <pre><code># user
{"phoneNumber":"112233", "firstName":"Hubert", "lastName":"Bonisseur de la Bath"}</code></pre>
                    </section>
                    <section data-background-image="img/livedemo.png" data-background-opacity="0.02">
                        <h3>KStream</h3>
                        <img data-src="img/livedemoKStream2.png">
                        <pre><code># sms enrichi
{
    "firstNameEmitter":"Hubert",
    "lastNameEmitter":"Bonisseur de la Bath",
    "phoneNumberEmitter":"112233",
    "message":"Coucou !",
    "phoneNumberReceiver":"907256"
}</code></pre>
                    </section>
                </section>
            </div>
        </div>

        <script src="dist/reveal.js"></script>
        <script src="plugin/notes/notes.js"></script>
        <script src="plugin/markdown/markdown.js"></script>
        <script src="plugin/highlight/highlight.js"></script>
        <script src="plugin/verticator/verticator.js"></script>
        <script>
            // More info about initialization & config:
            // - https://revealjs.com/initialization/
            // - https://revealjs.com/config/
            Reveal.initialize({
                hash: true,
                slideNumber: 'c/t',
                verticator: { darktheme: true },
                allottedTime: 30 * 60 * 1000, // 30 minutes
                // Learn about plugins: https://revealjs.com/plugins/
                plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, Verticator ],
                dependencies: [{ src: 'plugin/elapsed-time-bar/elapsed-time-bar.js' }]
            });
        </script>
    </body>
</html>
